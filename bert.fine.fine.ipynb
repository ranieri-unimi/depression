{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PFnNQBCIsOY"
      },
      "source": [
        "# col cuore in gola"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iZr-3elIsOh"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import json\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip datasets.zip"
      ],
      "metadata": {
        "id": "2EAmV4NpLElz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn83Lmv-IsOn"
      },
      "source": [
        "## fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "527tDlTxIsOo"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments, AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade pandas transformers datasets"
      ],
      "metadata": {
        "id": "6pWsLMHCLQPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUISG7cEIsOp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw3nGg9VIsOr"
      },
      "source": [
        "- https://github.com/rafalposwiata/depression-detection-lt-edi-2022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBlyApTTIsOs"
      },
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfM4wVwjIsOt"
      },
      "outputs": [],
      "source": [
        "data_text = \"\"\n",
        "\n",
        "for filename in sorted([\"ds\", \"ts_hs\", \"ts_ht\"]):\n",
        "    with open(Path(\"datasets\", \"task_0\", f\"{filename}.tsv\"), \"rt\", encoding=\"utf8\") as f:\n",
        "        data_text += f.read()\n",
        "\n",
        "df = pd.read_csv(StringIO(data_text), sep=\"\\t\")\n",
        "# dup_idx = df.index.difference(df.drop_duplicates().index)\n",
        "# df.loc[dup_idx]\n",
        "df = df.drop_duplicates().reset_index(names=\"old_idx\").reset_index(names=\"new_idx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twIV12teIsOu"
      },
      "source": [
        "train test indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZU5cJFYfIsOv"
      },
      "outputs": [],
      "source": [
        "lookup = df.set_index(\"old_idx\")[\"new_idx\"]\n",
        "pth = Path(\"datasets\", \"task_0\", \"train_test_splitting.json\")\n",
        "idx = json.load(open(pth, \"rt\"))\n",
        "idx = {k: [lookup[i] for i in lst if i in lookup] for k, lst in idx.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26nG-z-FIsOw"
      },
      "outputs": [],
      "source": [
        "x, y = df[\"pp_text\"], df[\"label\"]\n",
        "x_train, x_test = x.loc[idx[\"train\"]], x.loc[idx[\"test\"]]\n",
        "y_train, y_test = y.loc[idx[\"train\"]], y.loc[idx[\"test\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOnXSQ2DIsOx"
      },
      "outputs": [],
      "source": [
        "dataset = {\n",
        "    \"train\": datasets.Dataset.from_list([{\"label\": int(y), \"text\": str(x)} for y, x in zip(y_train, x_train)]),\n",
        "    \"test\": datasets.Dataset.from_list([{\"label\": int(y), \"text\": str(x)} for y, x in zip(y_test, x_test)]),\n",
        "}\n",
        "\n",
        "dataset =  datasets.DatasetDict(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXTh6iiGIsOy"
      },
      "source": [
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlGSklPYIsOz"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"ShreyaR/finetuned-roberta-depression\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBJC7q6lIsOz"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZirZbsZfIsO1"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_BMnnsPIsO1"
      },
      "outputs": [],
      "source": [
        "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKIO_IwLIsO2"
      },
      "source": [
        "finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL7ooHkQIsO3"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"ShreyaR/finetuned-roberta-depression\") # \"rafalposwiata/deproberta-large-depression\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrYLHxQTIsO3"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    \"test-trainer\",\n",
        "    # no_cuda=True,\n",
        "    seed=42,\n",
        "    # per_device_train_batch_size=1,\n",
        "    # gradient_accumulation_steps=8,\n",
        "    # gradient_checkpointing=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLexXSWsIsO5"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    # eval_dataset=tokenized_datasets[\"eval\"],\n",
        "    # data_collator=data_collator, \n",
        "    # tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PKp7PXLIsO6"
      },
      "outputs": [],
      "source": [
        "# trainer.train()\n",
        "# predictions = trainer.predict(tokenized_datasets[\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzpM3WFzIsO6"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "final hiddden embedding"
      ],
      "metadata": {
        "id": "2wpToWY8muaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "voc2hidden = trainer.model.get_input_embeddings()"
      ],
      "metadata": {
        "id": "GcnTAeiAi9Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# te_lst = []\n",
        "# for text in dataset[\"test\"][\"text\"]:\n",
        "#   input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(\"cuda\")\n",
        "#   hid = voc2hidden(input_ids)\n",
        "#   te_lst.append((text, hid))"
      ],
      "metadata": {
        "id": "d3PzhXoEjIjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "te_lst = pickle.load(open(\"text.w.hidden.pkl\", \"rb\"))"
      ],
      "metadata": {
        "id": "ers38Ul8oUW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HpUPQG5DjvH"
      },
      "outputs": [],
      "source": [
        "dataset[\"test\"][-1], dataset[\"test\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mTUbVgkIsO8"
      },
      "source": [
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S99SeEksF1y-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uf3cVpvIsO9"
      },
      "outputs": [],
      "source": [
        "y_fine = pickle.load(open(\"predictions/fine.pkl\", \"rb\"))\n",
        "y_raw = pickle.load(open(\"predictions/raw.pkl\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROQbVJXwIsO-"
      },
      "outputs": [],
      "source": [
        "y_true = y_raw[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IDscDwUIsO_"
      },
      "outputs": [],
      "source": [
        "y_fine = [ 1 if p < n else 0 for p, n in y_fine[0]]\n",
        "y_raw = [ 1 if p < n else 0 for p, n in y_raw[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWpVzyYlIsO_"
      },
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_raw)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(3, 3))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuWAJ5bIIsPA"
      },
      "outputs": [],
      "source": [
        "print('Precision:', precision_score(y_true, y_raw))\n",
        "print('Recall: ', recall_score(y_true, y_raw))\n",
        "print('Accuracy: ',  accuracy_score(y_true, y_raw))\n",
        "print('F1 Score: ',  f1_score(y_true, y_raw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRkUFVd1FvR_"
      },
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_fine)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(3, 3))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7X6ks_LGLID"
      },
      "outputs": [],
      "source": [
        "print('Precision:', precision_score(y_true, y_fine))\n",
        "print('Recall: ', recall_score(y_true, y_fine))\n",
        "print('Accuracy: ',  accuracy_score(y_true, y_fine))\n",
        "print('F1 Score: ',  f1_score(y_true, y_fine))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "group = [ ]\n",
        "for i, v in enumerate(zip(y_fine, y_true)):\n",
        "    match v:\n",
        "        case (0,0):\n",
        "            group.append(\"TN\")\n",
        "        case (1,1):\n",
        "            group.append(\"TP\")\n",
        "        case (0,1):\n",
        "            group.append(\"FN\")\n",
        "        case (1,0):\n",
        "            group.append(\"FP\")\n",
        "        case _:\n",
        "            raise ValueError(\"!\")            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Counter(group)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kHtq9c0eIsPC"
      },
      "source": [
        "## what models do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB_xgltZIsPD"
      },
      "source": [
        "tf idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiB5oT9SIsPE"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.spatial import distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fISi-7kJIsPE"
      },
      "outputs": [],
      "source": [
        "vect = TfidfVectorizer()\n",
        "tfidf_mx = vect.fit_transform(x_test)\n",
        "words = vect.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaNXLoHSIsPF"
      },
      "outputs": [],
      "source": [
        "type(tfidf_mx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a, b = tfidf_mx.shape\n",
        "tiv = np.zeros((a,b))\n",
        "for i in tqdm(range(a)):\n",
        "    for j in range(b):\n",
        "        tiv = tfidf_mx[i,j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj-dVX9bIsPF"
      },
      "outputs": [],
      "source": [
        "# cosine_tfidf = np.array([ [ distance.cosine(tmp[i],tmp[j]) for i in range(a)] for i in tqdm(range(a))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm6gXJ-mIsPH"
      },
      "source": [
        "sintactic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5bQJG7iIsPI"
      },
      "outputs": [],
      "source": [
        "def tokenize(text):\n",
        "    for match in re.finditer(r'\\w+', text, re.UNICODE):\n",
        "        yield match.group(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXjAYv88IsPJ"
      },
      "outputs": [],
      "source": [
        "import liwc\n",
        "parse, category_names = liwc.load_token_parser('dic/LIWC.dic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfHjiOiyIsPK"
      },
      "outputs": [],
      "source": [
        "K = len(category_names)\n",
        "N = len(x_test)\n",
        "\n",
        "kat_lookup = dict(zip(category_names, range(K)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alvUG9zKIsPL"
      },
      "outputs": [],
      "source": [
        "kat_freq = np.zeros((N, K))\n",
        "for n, text in enumerate(x_test):\n",
        "    for t in tokenize(text):\n",
        "        for m in parse(t):\n",
        "            k = kat_lookup[m]\n",
        "            kat_freq[n,k] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJF1VyVTIsPM"
      },
      "outputs": [],
      "source": [
        "cosine_mx = np.zeros((N,N))\n",
        "for i in tqdm(range(N)):\n",
        "    for j in range(N):\n",
        "        cosine_mx[i,j] = distance.cosine(kat_freq[i], kat_freq[j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO3N2ItTIsPN"
      },
      "outputs": [],
      "source": [
        "# THRESHOLD = 0.5\n",
        "# np.sign(cosine_mx - THRESHOLD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NC = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "X_embedded = TSNE(n_components=NC, learning_rate='auto',\n",
        "                  init='random', perplexity=3).fit_transform(cosine_mx)\n",
        "X_embedded.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oghbUZ2tIsPN"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=NC)\n",
        "new_coord = pca.fit_transform(cosine_mx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGvpd4y-IsPO"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaABXniyIsPO"
      },
      "outputs": [],
      "source": [
        "labels = {\n",
        "    str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
        "    for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
        "}\n",
        "\n",
        "fig = px.scatter_matrix(\n",
        "    new_coord, # X_embedded,\n",
        "    labels=labels,\n",
        "    dimensions=range(NC),\n",
        "    color=group,\n",
        "    height=1000,\n",
        ")\n",
        "fig.update_traces(diagonal_visible=False)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.2 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3a03f457ba8100ed956a9dead337cf895f8e146c4ebc145127222e1f06f191e5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}