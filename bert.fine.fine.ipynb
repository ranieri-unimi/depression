{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dn83Lmv-IsOn"
      },
      "source": [
        "# RoBERTa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iZr-3elIsOh"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import json\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EAmV4NpLElz"
      },
      "outputs": [],
      "source": [
        "# !unzip datasets.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "527tDlTxIsOo"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorWithPadding,\n",
        "    AutoModelForSequenceClassification,\n",
        ")\n",
        "from datasets import load_dataset\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pWsLMHCLQPG"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade pandas transformers datasets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUISG7cEIsOp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw3nGg9VIsOr"
      },
      "source": [
        "- https://github.com/rafalposwiata/depression-detection-lt-edi-2022"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CBlyApTTIsOs"
      },
      "source": [
        "Loading and mergin dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfM4wVwjIsOt"
      },
      "outputs": [],
      "source": [
        "data_text = \"\"\n",
        "\n",
        "for filename in sorted([\"ds\", \"ts_hs\", \"ts_ht\"]):\n",
        "    with open(\n",
        "        Path(\"datasets\", \"task_0\", f\"{filename}.tsv\"), \"rt\", encoding=\"utf8\"\n",
        "    ) as f:\n",
        "        data_text += f.read()\n",
        "\n",
        "df = pd.read_csv(StringIO(data_text), sep=\"\\t\")\n",
        "df = df.drop_duplicates().reset_index(names=\"old_idx\").reset_index(names=\"new_idx\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "twIV12teIsOu"
      },
      "source": [
        "splitting the dataset in training and testing (following previous works)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZU5cJFYfIsOv"
      },
      "outputs": [],
      "source": [
        "lookup = df.set_index(\"old_idx\")[\"new_idx\"]\n",
        "pth = Path(\"datasets\", \"task_0\", \"train_test_splitting.json\")\n",
        "idx = json.load(open(pth, \"rt\"))\n",
        "idx = {k: [lookup[i] for i in lst if i in lookup] for k, lst in idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26nG-z-FIsOw"
      },
      "outputs": [],
      "source": [
        "x, y = df[\"pp_text\"], df[\"label\"]\n",
        "x_train, x_test = x.loc[idx[\"train\"]], x.loc[idx[\"test\"]]\n",
        "y_train, y_test = y.loc[idx[\"train\"]].astype(int), y.loc[idx[\"test\"]].astype(int)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "converting the dataset in HuggingFace format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOnXSQ2DIsOx"
      },
      "outputs": [],
      "source": [
        "dataset = {\n",
        "    \"train\": datasets.Dataset.from_list(\n",
        "        [{\"label\": int(y), \"text\": str(x)} for y, x in zip(y_train, x_train)]\n",
        "    ),\n",
        "    \"test\": datasets.Dataset.from_list(\n",
        "        [{\"label\": int(y), \"text\": str(x)} for y, x in zip(y_test, x_test)]\n",
        "    ),\n",
        "}\n",
        "\n",
        "dataset = datasets.DatasetDict(dataset)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "some example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HpUPQG5DjvH"
      },
      "outputs": [],
      "source": [
        "dataset[\"test\"][-1], dataset[\"test\"][0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FXTh6iiGIsOy"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlGSklPYIsOz"
      },
      "outputs": [],
      "source": [
        "tokenizer_hf = AutoTokenizer.from_pretrained(\"ShreyaR/finetuned-roberta-depression\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBJC7q6lIsOz"
      },
      "outputs": [],
      "source": [
        "def to_hf_tokens(examples):\n",
        "    return tokenizer_hf(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZirZbsZfIsO1"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = dataset.map(to_hf_tokens, batched=True)\n",
        "tokenized_datasets.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_BMnnsPIsO1"
      },
      "outputs": [],
      "source": [
        "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NKIO_IwLIsO2"
      },
      "source": [
        "### Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL7ooHkQIsO3"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"ShreyaR/finetuned-roberta-depression\",\n",
        "    # \"rafalposwiata/deproberta-large-depression\",\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting ```gradient accumulation``` if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrYLHxQTIsO3"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    \"test-trainer\",\n",
        "    # no_cuda=True,\n",
        "    seed=42,\n",
        "    # per_device_train_batch_size=1,\n",
        "    # gradient_accumulation_steps=8,\n",
        "    # gradient_checkpointing=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLexXSWsIsO5"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    # eval_dataset=tokenized_datasets[\"eval\"],\n",
        "    # data_collator=data_collator,\n",
        "    # tokenizer=tokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PKp7PXLIsO6"
      },
      "outputs": [],
      "source": [
        "# trainer.train()\n",
        "# predictions = trainer.predict(tokenized_datasets[\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzpM3WFzIsO6"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "restoring results of predicion from pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uf3cVpvIsO9"
      },
      "outputs": [],
      "source": [
        "y_fine = pickle.load(open(\"predictions/fine.pkl\", \"rb\"))\n",
        "y_raw = pickle.load(open(\"predictions/raw.pkl\", \"rb\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2mTUbVgkIsO8"
      },
      "source": [
        "### Predicition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S99SeEksF1y-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROQbVJXwIsO-"
      },
      "outputs": [],
      "source": [
        "y_true = y_raw[1]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using 0.5 as threshold to convert logit to binary predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IDscDwUIsO_"
      },
      "outputs": [],
      "source": [
        "y_fine = [ 1 if p < n else 0 for p, n in y_fine[0]]\n",
        "y_raw = [ 1 if p < n else 0 for p, n in y_raw[0]]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Before Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWpVzyYlIsO_"
      },
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_raw)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(2, 2))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(\n",
        "            x=j,\n",
        "            y=i,\n",
        "            s=conf_matrix[i, j],\n",
        "            va=\"center\",\n",
        "            ha=\"center\",\n",
        "            size=\"large\",\n",
        "        )\n",
        "\n",
        "plt.xlabel(\"Predictions\", fontsize=14)\n",
        "plt.ylabel(\"Actuals\", fontsize=14)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuWAJ5bIIsPA"
      },
      "outputs": [],
      "source": [
        "print(\"Precision:\", precision_score(y_true, y_raw))\n",
        "print(\"Recall: \", recall_score(y_true, y_raw))\n",
        "print(\"Accuracy: \", accuracy_score(y_true, y_raw))\n",
        "print(\"F1 Score: \", f1_score(y_true, y_raw))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### After Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRkUFVd1FvR_"
      },
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_fine)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(2, 2))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(\n",
        "            x=j,\n",
        "            y=i,\n",
        "            s=conf_matrix[i, j],\n",
        "            va=\"center\",\n",
        "            ha=\"center\",\n",
        "            size=\"large\",\n",
        "        )\n",
        "\n",
        "plt.xlabel(\"Predictions\", fontsize=14)\n",
        "plt.ylabel(\"Actuals\", fontsize=14)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7X6ks_LGLID"
      },
      "outputs": [],
      "source": [
        "print(\"Precision:\", precision_score(y_true, y_fine))\n",
        "print(\"Recall: \", recall_score(y_true, y_fine))\n",
        "print(\"Accuracy: \", accuracy_score(y_true, y_fine))\n",
        "print(\"F1 Score: \", f1_score(y_true, y_fine))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "saving classification categories, for later purpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "group = []\n",
        "for i, v in enumerate(zip(y_fine, y_true)):\n",
        "    match v:\n",
        "        case (0, 0):\n",
        "            group.append(\"TN\")\n",
        "        case (1, 1):\n",
        "            group.append(\"TP\")\n",
        "        case (0, 1):\n",
        "            group.append(\"FN\")\n",
        "        case (1, 0):\n",
        "            group.append(\"FP\")\n",
        "        case _:\n",
        "            raise ValueError(\"!\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kHtq9c0eIsPC"
      },
      "source": [
        "## Explain Results"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hidden Embeddings"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To give an interpretation of how RoBERTa has predicted labels, we're going to use a lexical approach.\n",
        "\n",
        "LIWC assigns words to different categories, such as pronouns, affective words, and cognitive processes, and provides a numerical score for each category based on the frequency of the words in the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXjAYv88IsPJ"
      },
      "outputs": [],
      "source": [
        "import liwc\n",
        "parse, category_names = liwc.load_token_parser('dic/LIWC2007_English080730.dic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfHjiOiyIsPK"
      },
      "outputs": [],
      "source": [
        "K = len(category_names)\n",
        "N = len(x_test)\n",
        "\n",
        "kat_lookup = dict(zip(category_names, range(K)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "defining a function to stem / tokenize words, in order to let liwc match and count them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5bQJG7iIsPI"
      },
      "outputs": [],
      "source": [
        "def to_liwc_tokens(text):\n",
        "    for match in re.finditer(r\"\\w+\", text, re.UNICODE):\n",
        "        yield match.group(0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2wpToWY8muaF"
      },
      "source": [
        "extracting the last hidden embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcnTAeiAi9Ut"
      },
      "outputs": [],
      "source": [
        "voc2hidden = trainer.model.get_input_embeddings()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extracting lexical embedding and RoBERTa embadding for each document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_lex = []\n",
        "x_sem = []\n",
        "w_grp = []\n",
        "\n",
        "for n in tqdm(range(N)):\n",
        "    text = x_test.iloc[n]\n",
        "    kat_freq = np.zeros(K)\n",
        "\n",
        "    for t in to_liwc_tokens(text):\n",
        "        for m in parse(t):\n",
        "            k = kat_lookup[m]\n",
        "            kat_freq[k] += 1\n",
        "\n",
        "    s = kat_freq.sum()\n",
        "    if not s:\n",
        "        continue\n",
        "\n",
        "    kat_freq /= s\n",
        "\n",
        "    input_ids = tokenizer_hf.encode(text, return_tensors=\"pt\").to(\"cuda\")\n",
        "    tens = voc2hidden(input_ids)\n",
        "    if len(tens[0]) > 512:\n",
        "        continue\n",
        "    cls_token = tens[0][0]\n",
        "\n",
        "    x_sem.append(cls_token.to(\"cpu\").detach().numpy())\n",
        "    y_lex.append(kat_freq)\n",
        "    w_grp.append(group[n])\n",
        "\n",
        "\n",
        "y_lex = np.array(y_lex)\n",
        "x_sem = np.array(x_sem)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Regressing lexical embedding over semantic embedding with Ridge Regression\n",
        "\n",
        "The ridge regression still take into account all the independent variable (rather than the ElasticNet), but penalize the  less relevant ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import ElasticNet, Ridge, LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# e_reg = ElasticNet(random_state=42)\n",
        "# e_reg.fit(x_sem, y_lex)\n",
        "\n",
        "# print(e_reg.coef_)\n",
        "# # print(e_reg.intercept_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ridge_reg = Ridge(alpha=0.05)\n",
        "ridge_reg.fit(x_sem, y_lex)\n",
        "\n",
        "# print(ridge_reg.coef_)\n",
        "# print(ridge_reg.intercept_)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting the coefficients of hidden semantic embeddings for each dependent lexical probability (matrix shape only for visualization purpose)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_coeff(category):\n",
        "    i = category_names.index(category)\n",
        "    ax = sns.heatmap(\n",
        "        (ridge_reg.coef_[i]//1e-11).reshape((32, 24)),\n",
        "        cmap=sns.color_palette(\"vlag\", as_cmap=True),\n",
        "    )\n",
        "    ax.set(\n",
        "        xticklabels=[],\n",
        "        yticklabels=[],\n",
        "        title=category.upper(),\n",
        "    )\n",
        "    ax.tick_params(bottom=False, left=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_coeff(\"death\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_coeff(\"posemo\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For well known lexical opposite, coefficient shoud be distant:\n",
        "\n",
        "checking by element-wise product (smaller is better)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for a, b in [[\"posemo\", \"negemo\"], [\"i\", \"past\"], [\"adverb\", \"negate\"]]:\n",
        "    i = category_names.index(a)\n",
        "    j = category_names.index(b)\n",
        "    v = np.multiply(ridge_reg.coef_[i], ridge_reg.coef_[j])\n",
        "    # v = np.dot(ridge_reg.coef_[i], ridge_reg.coef_[j])\n",
        "    print(v.max())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TEST_0 = \"One of the most important things you could realize is that I found me alone\"\n",
        "TEST_1 = x_test.iloc[3]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extracting attention from CLS to other tokens of the last RoBERTa layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def word_prob(text, to_filter=False):\n",
        "    input_ids = tokenizer_hf.encode(text, return_tensors=\"pt\").to(\"cuda\")\n",
        "    if input_ids.shape[-1] > 512:\n",
        "        return [], []\n",
        "    outputs = trainer.model(\n",
        "        input_ids,\n",
        "        output_attentions=True,\n",
        "        # attention_mask=attention_mask,\n",
        "    )\n",
        "    attention_weights = outputs[-1]\n",
        "    attention_norms = attention_weights[-1][0, :, :, :].norm(dim=0)\n",
        "    word_score = attention_norms[0, 1:-1].cpu().detach().numpy()\n",
        "\n",
        "    word_name = [tokenizer_hf.decode(e).lower().strip() for e in input_ids[0, 1:-1]]\n",
        "\n",
        "    if to_filter:\n",
        "        word_score, word_name = list(\n",
        "            zip(\n",
        "                *[\n",
        "                    (word_score[i], word_name[i])\n",
        "                    for i in range(len(word_name))\n",
        "                    if len(word_name[i]) > 1 and not word_name[i].startswith(\"depress\")\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return word_name, word_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_text_wc(text, score=None):\n",
        "    wc = WordCloud()\n",
        "    if score is None:\n",
        "        wc.generate(text)\n",
        "    else:\n",
        "        wc.generate_from_frequencies(dict(zip(text, score)))\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(wc)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plottig word cloud were words are weighted by attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_name, word_score = word_prob(TEST_0)\n",
        "plot_text_wc(word_name, word_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_name, word_score = word_prob(TEST_1, to_filter=True)\n",
        "plot_text_wc(word_name, word_score)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plottig word cloud for False Positive / False Nagative class "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_fp = [x_test.iloc[i] for i,g in enumerate(w_grp) if g == \"FP\"]\n",
        "test_fn = [x_test.iloc[i] for i,g in enumerate(w_grp) if g == \"FN\"]\n",
        "test_tp = [x_test.iloc[i] for i,g in enumerate(w_grp) if g == \"TP\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_top_k_words(a, how_many=4):\n",
        "    bag = []\n",
        "    for text in a:\n",
        "        word_name, word_score = word_prob(text)\n",
        "        if len(word_name) < how_many:  # phrase too short\n",
        "            continue\n",
        "        for i in np.argpartition(word_score, -how_many)[-how_many:]:\n",
        "            word = word_name[i]\n",
        "            if len(word) > 2 and not word.startswith(\"depress\"):\n",
        "                bag.append(word)\n",
        "\n",
        "    f_text = \" \".join(bag)\n",
        "    plot_text_wc(f_text)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualizing how attention wordclouds are different between classification groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_top_k_words(test_tp, how_many=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_top_k_words(test_fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_top_k_words(test_fn)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### failed attempts - similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.spatial import distance\n",
        "\n",
        "import plotly.express as px"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we compute the cosine similiarity between all pairs of document embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJF1VyVTIsPM"
      },
      "outputs": [],
      "source": [
        "M = len(y_lex)\n",
        "cosine_mx = np.zeros((M,M))\n",
        "for i in tqdm(range(M)):\n",
        "    for j in range(M):\n",
        "        cosine_mx[i,j] = distance.cosine(y_lex[i], y_lex[j])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We reduce the dimentionality of the embeddings to visualize if missclassification is somehow related to embedding position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NC = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_embedded = TSNE(n_components=NC, learning_rate='auto',\n",
        "#                   init='random', perplexity=3).fit_transform(cosine_mx)\n",
        "# X_embedded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oghbUZ2tIsPN"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=NC)\n",
        "new_coord = pca.fit_transform([e for e,g in zip(cosine_mx,w_grp) if g != \"TN\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaABXniyIsPO"
      },
      "outputs": [],
      "source": [
        "labels = {\n",
        "    str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
        "    for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
        "}\n",
        "\n",
        "fig = px.scatter_matrix(\n",
        "    new_coord, # X_embedded,\n",
        "    labels=labels,\n",
        "    dimensions=range(NC),\n",
        "    color=[g for g in w_grp if g != \"TN\"],\n",
        "    height=1000,\n",
        ")\n",
        "fig.update_traces(diagonal_visible=False)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB_xgltZIsPD"
      },
      "source": [
        "tf idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fISi-7kJIsPE"
      },
      "outputs": [],
      "source": [
        "vect = TfidfVectorizer()\n",
        "tfidf_mx = vect.fit_transform(x_test)\n",
        "words = vect.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# a, b = tfidf_mx.shape\n",
        "# tiv = np.zeros((a,b))\n",
        "# for i in tqdm(range(a)):\n",
        "#     for j in range(b):\n",
        "#         tiv = tfidf_mx[i,j]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.2 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3a03f457ba8100ed956a9dead337cf895f8e146c4ebc145127222e1f06f191e5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
