{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1PFnNQBCIsOY"
      },
      "source": [
        "# transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iZr-3elIsOh"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from io import StringIO\n",
        "import json\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from collections import Counter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EAmV4NpLElz"
      },
      "outputs": [],
      "source": [
        "# !unzip datasets.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn83Lmv-IsOn"
      },
      "source": [
        "## fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "527tDlTxIsOo"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorWithPadding,\n",
        "    AutoModelForSequenceClassification,\n",
        ")\n",
        "from datasets import load_dataset\n",
        "import datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pWsLMHCLQPG"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade pandas transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUISG7cEIsOp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.get_device_name(0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw3nGg9VIsOr"
      },
      "source": [
        "- https://github.com/rafalposwiata/depression-detection-lt-edi-2022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBlyApTTIsOs"
      },
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfM4wVwjIsOt"
      },
      "outputs": [],
      "source": [
        "data_text = \"\"\n",
        "\n",
        "for filename in sorted([\"ds\", \"ts_hs\", \"ts_ht\"]):\n",
        "    with open(\n",
        "        Path(\"datasets\", \"task_0\", f\"{filename}.tsv\"), \"rt\", encoding=\"utf8\"\n",
        "    ) as f:\n",
        "        data_text += f.read()\n",
        "\n",
        "df = pd.read_csv(StringIO(data_text), sep=\"\\t\")\n",
        "# dup_idx = df.index.difference(df.drop_duplicates().index)\n",
        "# df.loc[dup_idx]\n",
        "df = df.drop_duplicates().reset_index(names=\"old_idx\").reset_index(names=\"new_idx\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twIV12teIsOu"
      },
      "source": [
        "train test indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZU5cJFYfIsOv"
      },
      "outputs": [],
      "source": [
        "lookup = df.set_index(\"old_idx\")[\"new_idx\"]\n",
        "pth = Path(\"datasets\", \"task_0\", \"train_test_splitting.json\")\n",
        "idx = json.load(open(pth, \"rt\"))\n",
        "idx = {k: [lookup[i] for i in lst if i in lookup] for k, lst in idx.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26nG-z-FIsOw"
      },
      "outputs": [],
      "source": [
        "x, y = df[\"pp_text\"], df[\"label\"]\n",
        "x_train, x_test = x.loc[idx[\"train\"]], x.loc[idx[\"test\"]]\n",
        "y_train, y_test = y.loc[idx[\"train\"]], y.loc[idx[\"test\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOnXSQ2DIsOx"
      },
      "outputs": [],
      "source": [
        "dataset = {\n",
        "    \"train\": datasets.Dataset.from_list(\n",
        "        [{\"label\": int(y), \"text\": str(x)} for y, x in zip(y_train, x_train)]\n",
        "    ),\n",
        "    \"test\": datasets.Dataset.from_list(\n",
        "        [{\"label\": int(y), \"text\": str(x)} for y, x in zip(y_test, x_test)]\n",
        "    ),\n",
        "}\n",
        "\n",
        "dataset = datasets.DatasetDict(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HpUPQG5DjvH"
      },
      "outputs": [],
      "source": [
        "dataset[\"test\"][-1], dataset[\"test\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXTh6iiGIsOy"
      },
      "source": [
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlGSklPYIsOz"
      },
      "outputs": [],
      "source": [
        "tokenizer_hf = AutoTokenizer.from_pretrained(\"ShreyaR/finetuned-roberta-depression\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBJC7q6lIsOz"
      },
      "outputs": [],
      "source": [
        "def to_hf_tokens(examples):\n",
        "    return tokenizer_hf(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "\n",
        "tokenized_datasets = dataset.map(to_hf_tokens, batched=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZirZbsZfIsO1"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_BMnnsPIsO1"
      },
      "outputs": [],
      "source": [
        "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKIO_IwLIsO2"
      },
      "source": [
        "finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL7ooHkQIsO3"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"ShreyaR/finetuned-roberta-depression\",\n",
        "    # \"rafalposwiata/deproberta-large-depression\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrYLHxQTIsO3"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    \"test-trainer\",\n",
        "    # no_cuda=True,\n",
        "    seed=42,\n",
        "    # per_device_train_batch_size=1,\n",
        "    # gradient_accumulation_steps=8,\n",
        "    # gradient_checkpointing=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLexXSWsIsO5"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    # eval_dataset=tokenized_datasets[\"eval\"],\n",
        "    # data_collator=data_collator,\n",
        "    # tokenizer=tokenizer,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PKp7PXLIsO6"
      },
      "outputs": [],
      "source": [
        "# trainer.train()\n",
        "# predictions = trainer.predict(tokenized_datasets[\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzpM3WFzIsO6"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wpToWY8muaF"
      },
      "source": [
        "final hiddden embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcnTAeiAi9Ut"
      },
      "outputs": [],
      "source": [
        "voc2hidden = trainer.model.get_input_embeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3PzhXoEjIjz"
      },
      "outputs": [],
      "source": [
        "# te_lst = []\n",
        "# for text in dataset[\"test\"][\"text\"]:\n",
        "#   input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(\"cuda\")\n",
        "#   hid = voc2hidden(input_ids)\n",
        "#   te_lst.append((text, hid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ers38Ul8oUW6"
      },
      "outputs": [],
      "source": [
        "# te_lst = pickle.load(open(\"text.w.hidden.pkl\", \"rb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mTUbVgkIsO8"
      },
      "source": [
        "metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S99SeEksF1y-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uf3cVpvIsO9"
      },
      "outputs": [],
      "source": [
        "y_fine = pickle.load(open(\"predictions/fine.pkl\", \"rb\"))\n",
        "y_raw = pickle.load(open(\"predictions/raw.pkl\", \"rb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROQbVJXwIsO-"
      },
      "outputs": [],
      "source": [
        "y_true = y_raw[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IDscDwUIsO_"
      },
      "outputs": [],
      "source": [
        "y_fine = [ 1 if p < n else 0 for p, n in y_fine[0]]\n",
        "y_raw = [ 1 if p < n else 0 for p, n in y_raw[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWpVzyYlIsO_"
      },
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_raw)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(3, 3))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuWAJ5bIIsPA"
      },
      "outputs": [],
      "source": [
        "print('Precision:', precision_score(y_true, y_raw))\n",
        "print('Recall: ', recall_score(y_true, y_raw))\n",
        "print('Accuracy: ',  accuracy_score(y_true, y_raw))\n",
        "print('F1 Score: ',  f1_score(y_true, y_raw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRkUFVd1FvR_"
      },
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_fine)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(3, 3))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7X6ks_LGLID"
      },
      "outputs": [],
      "source": [
        "print('Precision:', precision_score(y_true, y_fine))\n",
        "print('Recall: ', recall_score(y_true, y_fine))\n",
        "print('Accuracy: ',  accuracy_score(y_true, y_fine))\n",
        "print('F1 Score: ',  f1_score(y_true, y_fine))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "group = [ ]\n",
        "for i, v in enumerate(zip(y_fine, y_true)):\n",
        "    match v:\n",
        "        case (0,0):\n",
        "            group.append(\"TN\")\n",
        "        case (1,1):\n",
        "            group.append(\"TP\")\n",
        "        case (0,1):\n",
        "            group.append(\"FN\")\n",
        "        case (1,0):\n",
        "            group.append(\"FP\")\n",
        "        case _:\n",
        "            raise ValueError(\"!\")            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Counter(group)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kHtq9c0eIsPC"
      },
      "source": [
        "## what models do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB_xgltZIsPD"
      },
      "source": [
        "tf idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiB5oT9SIsPE"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.spatial import distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fISi-7kJIsPE"
      },
      "outputs": [],
      "source": [
        "vect = TfidfVectorizer()\n",
        "tfidf_mx = vect.fit_transform(x_test)\n",
        "words = vect.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaNXLoHSIsPF"
      },
      "outputs": [],
      "source": [
        "type(tfidf_mx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# a, b = tfidf_mx.shape\n",
        "# tiv = np.zeros((a,b))\n",
        "# for i in tqdm(range(a)):\n",
        "#     for j in range(b):\n",
        "#         tiv = tfidf_mx[i,j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj-dVX9bIsPF"
      },
      "outputs": [],
      "source": [
        "# cosine_tfidf = np.array([ [ distance.cosine(tmp[i],tmp[j]) for i in range(a)] for i in tqdm(range(a))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm6gXJ-mIsPH"
      },
      "source": [
        "sintactic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"like\t(02 134)125/464\t(02 134)126\t(02 134)126\t253\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5bQJG7iIsPI"
      },
      "outputs": [],
      "source": [
        "def to_liwc_tokens(text):\n",
        "    for match in re.finditer(r'\\w+', text, re.UNICODE):\n",
        "        yield match.group(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXjAYv88IsPJ"
      },
      "outputs": [],
      "source": [
        "import liwc\n",
        "parse, category_names = liwc.load_token_parser('dic/LIWC2007_English080730.dic')\n",
        "# parse, category_names = liwc.load_token_parser('dic/LIWC2001_English.dic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfHjiOiyIsPK"
      },
      "outputs": [],
      "source": [
        "K = len(category_names)\n",
        "N = len(x_test)\n",
        "\n",
        "kat_lookup = dict(zip(category_names, range(K)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.array([2,3,4]) / 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_snt = []\n",
        "x_sem = []\n",
        "w_grp = []\n",
        "\n",
        "for n in tqdm(range(N)):\n",
        "    text = x_test.iloc[n]\n",
        "    kat_freq = np.zeros(K)\n",
        "\n",
        "    for t in to_liwc_tokens(text):\n",
        "        for m in parse(t):\n",
        "            k = kat_lookup[m]\n",
        "            kat_freq[k] += 1\n",
        "\n",
        "    s = kat_freq.sum()\n",
        "    if not s:\n",
        "        continue\n",
        "\n",
        "    kat_freq /= s\n",
        "    \n",
        "    input_ids = tokenizer_hf.encode(text, return_tensors=\"pt\").to(\"cuda\")\n",
        "    tens = voc2hidden(input_ids)\n",
        "    if len(tens[0]) > 512:\n",
        "        continue\n",
        "    cls_token = tens[0][0]\n",
        "\n",
        "    x_sem.append(cls_token.to(\"cpu\").detach().numpy())\n",
        "    y_snt.append(kat_freq)\n",
        "    w_grp.append(group[n])\n",
        "\n",
        "\n",
        "y_snt = np.array(y_snt)\n",
        "x_sem = np.array(x_sem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import ElasticNet, Ridge, LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "e_reg = ElasticNet(random_state=42)\n",
        "e_reg.fit(x_sem, y_snt)\n",
        "\n",
        "print(e_reg.coef_)\n",
        "# print(e_reg.intercept_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ridge_reg = Ridge(alpha=0.1)\n",
        "ridge_reg.fit(x_sem, y_snt)\n",
        "\n",
        "print(e_reg.coef_)\n",
        "print(e_reg.intercept_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "category_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_coeff(category):\n",
        "    i = category_names.index(category)\n",
        "    ax = sns.heatmap(\n",
        "        e_reg.coef_[i].reshape((32, 24)), cmap=sns.color_palette(\"vlag\", as_cmap=True)\n",
        "    )\n",
        "    ax.set(\n",
        "        xticklabels=[],\n",
        "        yticklabels=[],\n",
        "        title=category.upper(),\n",
        "    )\n",
        "    ax.tick_params(bottom=False, left=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_coeff(\"family\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_coeff(\"death\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_coeff(\"adverb\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJF1VyVTIsPM"
      },
      "outputs": [],
      "source": [
        "M = len(y_snt)\n",
        "cosine_mx = np.zeros((M,M))\n",
        "for i in tqdm(range(M)):\n",
        "    for j in range(M):\n",
        "        cosine_mx[i,j] = distance.cosine(y_snt[i], y_snt[j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO3N2ItTIsPN"
      },
      "outputs": [],
      "source": [
        "# THRESHOLD = 0.5\n",
        "# np.sign(cosine_mx - THRESHOLD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NC = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.manifold import TSNE\n",
        "# X_embedded = TSNE(n_components=NC, learning_rate='auto',\n",
        "#                   init='random', perplexity=3).fit_transform(cosine_mx)\n",
        "# X_embedded.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oghbUZ2tIsPN"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=NC)\n",
        "new_coord = pca.fit_transform([e for e,g in zip(cosine_mx,w_grp) if g != \"TN\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGvpd4y-IsPO"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaABXniyIsPO"
      },
      "outputs": [],
      "source": [
        "labels = {\n",
        "    str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
        "    for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
        "}\n",
        "\n",
        "fig = px.scatter_matrix(\n",
        "    new_coord, # X_embedded,\n",
        "    labels=labels,\n",
        "    dimensions=range(NC),\n",
        "    color=[g for g in w_grp if g != \"TN\"],\n",
        "    height=1000,\n",
        ")\n",
        "fig.update_traces(diagonal_visible=False)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.2 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3a03f457ba8100ed956a9dead337cf895f8e146c4ebc145127222e1f06f191e5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
